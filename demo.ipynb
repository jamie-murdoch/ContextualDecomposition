{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from os.path import join as oj\n",
    "sys.path.insert(1, oj(sys.path[0], 'train_model'))\n",
    "\n",
    "from train_model import sent_util\n",
    "\n",
    "import torch\n",
    "from torchtext import data, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train_model/results/best_snapshot_devacc_84.9770642201835_devloss_0.5329645872116089_iter_7000_model.pt\n",
      "loaded onto gpu...\n"
     ]
    }
   ],
   "source": [
    "# To train model, first run 'train.py' from train_model dir\n",
    "\n",
    "# get model\n",
    "snapshot_dir = 'train_model/results/'\n",
    "\n",
    "snapshot_file = oj(snapshot_dir, \n",
    "                    'best_snapshot_devacc_84.9770642201835_devloss_0.5329645872116089_iter_7000_model.pt')\n",
    "model = sent_util.get_model(snapshot_file)\n",
    "\n",
    "# get data\n",
    "inputs, answers, train_iterator, dev_iterator = sent_util.get_sst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting batches...\n"
     ]
    }
   ],
   "source": [
    "# Find sentence used in figure 2\n",
    "batch_nums = list(range(6920))\n",
    "data = sent_util.get_batches(batch_nums, train_iterator, dev_iterator) \n",
    "for ind in range(6919):\n",
    "    text = data[ind].text.data[:, 0]\n",
    "    words = [inputs.vocab.itos[i] for i in text]\n",
    "    if words[0] == 'it' and words[1] == \"'s\" and words[2] == 'easy':\n",
    "        high_level_comp_ind = ind\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 's easy to love robin tunney -- she 's pretty and she can act -- 0.545045315382\n",
      "but it gets harder and harder to understand her choices . -1.22609390466\n"
     ]
    }
   ],
   "source": [
    "# Produce CD importance scores for phrases used in figure 2\n",
    "pos, pos_irrel = sent_util.CD(data[high_level_comp_ind], model, start = 0, stop = 15)\n",
    "print(' '.join(words[:16]), pos[0] - pos[1])\n",
    "neg, neg_irrel = sent_util.CD(data[high_level_comp_ind], model, start = 16, stop = 26)\n",
    "print(' '.join(words[16:]), neg[0] - neg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07590632  0.28036043]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_model/model.py:30: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  lstm_out, self.hidden = self.lstm(vecs, self.hidden)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07590645  0.28036064]\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: CD is a decomposition, so an effective way to check for bugs is to verify that the decomposition holds (up to numerical errors)\n",
    "print(pos + pos_irrel)\n",
    "linear_bias = model.hidden_to_label.bias.data.cpu().numpy()\n",
    "print((model(data[high_level_comp_ind]).data.cpu().numpy() - linear_bias)[0])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
